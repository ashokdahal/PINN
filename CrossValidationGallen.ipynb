{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import GallenModel as ClassificationModelsimple\n",
    "import geopandas as gpd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainmodel(model,train_ds,val_ds):\n",
    "    \n",
    "    NUMBER_EPOCHS = 100\n",
    "    filepath='TrainedWeightsCrossVal'\n",
    "    BATCH_SIZE=32\n",
    "    \n",
    "    model_checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor=\"val_auc\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode=\"max\",\n",
    "        save_freq=\"epoch\",\n",
    "        options=None\n",
    "    )\n",
    "    print(type(train_ds))\n",
    "    hist = model.fit(train_ds,\n",
    "                     epochs=NUMBER_EPOCHS,\n",
    "                     batch_size=BATCH_SIZE,\n",
    "                     validation_data=val_ds,\n",
    "                    #  validation_split=0.2,#auto validate using 20% of random samples at each epoch\n",
    "                     verbose=1, callbacks=[model_checkpoint_callback],class_weight = {0: 1, 1: 5}\n",
    "\n",
    "                    )\n",
    "    return hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spatial cross validation\n",
    "\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  df = dataframe.copy()\n",
    "  labels = df.pop('Landslide')\n",
    "  df = {key: value.to_numpy()[:,tf.newaxis] for key, value in dataframe.items()}\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(batch_size)\n",
    "  return ds\n",
    "\n",
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "  # Create a layer that turns strings into integer indices.\n",
    "  if dtype == 'string':\n",
    "    index = layers.StringLookup(max_tokens=max_tokens)\n",
    "  # Otherwise, create a layer that turns integer values into integer indices.\n",
    "  else:\n",
    "    index = layers.IntegerLookup(max_tokens=max_tokens)\n",
    "\n",
    "  # Prepare a `tf.data.Dataset` that only yields the feature.\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the set of possible values and assign them a fixed integer index.\n",
    "  index.adapt(feature_ds)\n",
    "\n",
    "  # Encode the integer indices.\n",
    "  encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "\n",
    "  # Apply multi-hot encoding to the indices. The lambda function captures the\n",
    "  # layer, so you can use them, or include them in the Keras Functional model later.\n",
    "  return lambda feature: encoder(index(feature))\n",
    "\n",
    "def get_normalization_layer(name, dataset):\n",
    "  # Create a Normalization layer for the feature.\n",
    "  normalizer = layers.Normalization(axis=None)\n",
    "\n",
    "  # Prepare a Dataset that only yields the feature.\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the statistics of the data.\n",
    "  normalizer.adapt(feature_ds)\n",
    "\n",
    "  return normalizer\n",
    "\n",
    "def spatialCrossVal():\n",
    "    for i in range(1,11):\n",
    "        print(i)\n",
    "        all_inputs = []\n",
    "        encoded_features = []\n",
    "        \n",
    "        train_df=df[df.id!=i]\n",
    "        test_df=df[df.id==i]\n",
    "        print(f\"Number of train set{len(train_df)} and number of test set {len(test_df)}\")\n",
    " \n",
    "        exai_ds=df_to_dataset(train_df[['Est_m','Nrt_m','HC_m','VC_m','Slp_m','Prc_m','NDVI_m','PGA_Usgs','Sand_m','Silt_m','Clay_m','Bdod_m','GLG','Landslide']])\n",
    "        val_ds=df_to_dataset(test_df[['Est_m','Nrt_m','HC_m','VC_m','Slp_m','Prc_m','NDVI_m','PGA_Usgs','Sand_m','Silt_m','Clay_m','Bdod_m','GLG','Landslide']],shuffle=False)\n",
    "        y_test=test_df['Landslide'].to_numpy()\n",
    "        \n",
    "\n",
    "        for header in numerical_cols:\n",
    "          numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "          normalization_layer = get_normalization_layer(header, exai_ds)\n",
    "          encoded_numeric_col = normalization_layer(numeric_col)\n",
    "          all_inputs.append(numeric_col)\n",
    "          encoded_features.append(encoded_numeric_col)\n",
    "\n",
    "        for header in categorical_cols:\n",
    "          categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
    "          encoding_layer = get_category_encoding_layer(name=header,\n",
    "                                                      dataset=exai_ds,\n",
    "                                                      dtype='string',\n",
    "                                                      max_tokens=9)\n",
    "          encoded_categorical_col = encoding_layer(categorical_col)\n",
    "          all_inputs.append(categorical_col)\n",
    "          encoded_features.append(encoded_categorical_col)\n",
    "\n",
    "        clfmdl=ClassificationModelsimple.LandslideModel()\n",
    "        clfmdl.getclassificationModel(all_inputs=all_inputs, encoded_features=encoded_features)\n",
    "        clfmdl.getOptimizer()\n",
    "        clfmdl.compileModel()\n",
    "\n",
    "        trainmodel(clfmdl.model,exai_ds,val_ds)\n",
    "        model =  tf.keras.models.load_model(\"TrainedWeightsCrossVal/\")\n",
    "        preds=model.predict(val_ds)\n",
    "        np.save(f'crossval_resultsGallen/SpPredsrv1_{str(i)}.npy',preds)\n",
    "        np.save(f'crossval_resultsGallen/SpTruthsrv1_{str(i)}.npy',y_test)\n",
    "        del model,clfmdl\n",
    "        tf.keras.backend.clear_session()\n",
    "        i+=1\n",
    "def randomCrossVal(dfc):\n",
    "  kf = KFold(n_splits=10,random_state=42,shuffle=True)\n",
    "  kf.get_n_splits(df)\n",
    "  i=0\n",
    "  for train_index, test_index in kf.split(df):\n",
    "    print(i)\n",
    "    all_inputs = []\n",
    "    encoded_features = []\n",
    "    \n",
    "    #    df.iloc[train_index]\n",
    "    # df.iloc[test_index]\n",
    "    train_df=dfc.iloc[train_index]\n",
    "    test_df=dfc.iloc[test_index]\n",
    "    print(f\"Number of train set{len(train_df)} and number of test set {len(test_df)}\")\n",
    "\n",
    "    exai_ds=df_to_dataset(train_df[['Est_m','Nrt_m','HC_m','VC_m','Slp_m','Prc_m','NDVI_m','PGA_Usgs','Sand_m','Silt_m','Clay_m','Bdod_m','GLG','Landslide']])\n",
    "    val_ds=df_to_dataset(test_df[['Est_m','Nrt_m','HC_m','VC_m','Slp_m','Prc_m','NDVI_m','PGA_Usgs','Sand_m','Silt_m','Clay_m','Bdod_m','GLG','Landslide']],shuffle=False)\n",
    "    y_test=test_df['Landslide'].to_numpy()\n",
    "    \n",
    "\n",
    "    for header in numerical_cols:\n",
    "      numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "      normalization_layer = get_normalization_layer(header, exai_ds)\n",
    "      encoded_numeric_col = normalization_layer(numeric_col)\n",
    "      all_inputs.append(numeric_col)\n",
    "      encoded_features.append(encoded_numeric_col)\n",
    "\n",
    "    for header in categorical_cols:\n",
    "      categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
    "      encoding_layer = get_category_encoding_layer(name=header,\n",
    "                                                  dataset=exai_ds,\n",
    "                                                  dtype='string',\n",
    "                                                  max_tokens=9)\n",
    "      encoded_categorical_col = encoding_layer(categorical_col)\n",
    "      all_inputs.append(categorical_col)\n",
    "      encoded_features.append(encoded_categorical_col)\n",
    "\n",
    "    clfmdl=ClassificationModelsimple.LandslideModel()\n",
    "    clfmdl.getclassificationModel(all_inputs=all_inputs, encoded_features=encoded_features)\n",
    "    clfmdl.getOptimizer()\n",
    "    clfmdl.compileModel()\n",
    "\n",
    "    trainmodel(clfmdl.model,exai_ds,val_ds)\n",
    "    model =  tf.keras.models.load_model(\"TrainedWeightsCrossVal/\")\n",
    "    preds=model.predict(val_ds)\n",
    "    np.save(f'crossval_resultsGallen/RvPredsrv2_{str(i)}.npy',preds)\n",
    "    np.save(f'crossval_resultsGallen/RvTruthsrv2_{str(i)}.npy',y_test)\n",
    "    del model,clfmdl\n",
    "    tf.keras.backend.clear_session()\n",
    "    i+=1\n",
    "    # del clfmdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['GLG']\n",
    "numerical_cols=['Est_m', 'Nrt_m', 'HC_m', 'VC_m', 'Slp_m', 'Prc_m', 'NDVI_m', 'PGA_Usgs', 'Sand_m', 'Silt_m', 'Clay_m', 'Bdod_m']\n",
    "df=gpd.read_file('Data/NepalEqUSGSGallen.gpkg')\n",
    "df = df[df.Slp_m>10.0]\n",
    "spatialCrossVal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['GLG']\n",
    "numerical_cols=['Est_m', 'Nrt_m', 'HC_m', 'VC_m', 'Slp_m', 'Prc_m', 'NDVI_m', 'PGA_Usgs', 'Sand_m', 'Silt_m', 'Clay_m', 'Bdod_m']\n",
    "df=gpd.read_file('Data/NepalEqUSGSGallen.gpkg')\n",
    "df = df[df.Slp_m>10.0]\n",
    "randomCrossVal(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def roc_curve(y_true, y_prob, thresholds):\n",
    "\n",
    "    fpr = []\n",
    "    tpr = []\n",
    "\n",
    "    for threshold in thresholds:\n",
    "\n",
    "        y_pred = np.where(y_prob >= threshold, 1, 0)\n",
    "\n",
    "        fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "        tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "\n",
    "        fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "        tn = np.sum((y_pred == 0) & (y_true == 0))\n",
    "\n",
    "        fpr.append(fp / (fp + tn))\n",
    "        tpr.append(tp / (tp + fn))\n",
    "\n",
    "    return fpr, tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot \n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np \n",
    "from scipy.interpolate import interp1d\n",
    "figure(figsize=(4, 4), dpi=300)\n",
    "Aucs=[]\n",
    "fprs=[]\n",
    "tprs=[]\n",
    "for i in range(1,11):\n",
    "    preds=np.load(f'crossval_resultsGallen/SpPredsrv1_{str(i)}.npy')\n",
    "    truths=np.load(f'crossval_resultsGallen/SpTruthsrv1_{str(i)}.npy')\n",
    "    fpr,tpr = roc_curve(truths.flatten(),preds.flatten(),thresholds=np.linspace(0,1,500))\n",
    "    plt.plot(np.array(fpr),np.array(tpr),lw=0.5,color='grey')\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "    fpr,tpr,thresholds=sklearn.metrics.roc_curve(truths.flatten(), preds.flatten(),drop_intermediate=False)\n",
    "    Aucs.append(sklearn.metrics.auc(fpr,tpr))\n",
    "# \n",
    "median_idx = np.argsort(Aucs)[len(Aucs)//2]\n",
    "\n",
    "plt.plot(np.array(fprs)[median_idx],np.array(tprs)[median_idx],lw=0.5,color='g')\n",
    "\n",
    "\n",
    "# common_fpr = np.linspace(0.001, 1, 100)\n",
    "# interp_tpr1 = interp1d(np.array(fprs)[np.argmin(np.array(tprs),axis=0)].min(axis=0), np.array(tprs).min(axis=0), kind='linear')(common_fpr)\n",
    "# interp_tpr2 = interp1d(np.array(fprs)[np.argmax(np.array(tprs),axis=0)].max(axis=0), np.array(tprs).max(axis=0), kind='linear')(common_fpr)\n",
    "# plt.fill_between(common_fpr,interp_tpr1,interp_tpr2, color='grey')\n",
    "\n",
    "ax = plt.plot([0, 1], [0, 1], color=\"navy\", lw=1, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Spatial Crossvalidation\")\n",
    "# plt.text(0.38, 0.11,\"Accuracy=0.8131\")\n",
    "# plt.legend(loc=\"lower right\")\n",
    "plt.axis('square')\n",
    "plt.tight_layout()\n",
    "plt.savefig('PINNPlotsGallen/rocSpValrev1.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot \n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np \n",
    "figure(figsize=(4, 4), dpi=300)\n",
    "Aucs2=[]\n",
    "fprs=[]\n",
    "tprs=[]\n",
    "for i in range(0,10):\n",
    "    preds=np.load(f'crossval_resultsGallen/RvPredsrv2_{str(i)}.npy')\n",
    "    truths=np.load(f'crossval_resultsGallen/RvTruthsrv2_{str(i)}.npy')\n",
    "    fpr,tpr,thresholds=sklearn.metrics.roc_curve(truths.flatten(), preds.flatten())\n",
    "    plt.plot(\n",
    "        fpr,\n",
    "        tpr,\n",
    "        # color=\"darkorange\",\n",
    "        lw=0.25,\n",
    "        label=f\"RandomArea{str(i+1)}\",color='grey'\n",
    "    )\n",
    "    Aucs2.append(sklearn.metrics.auc(fpr,tpr))\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "\n",
    "median_idx = np.argsort(Aucs2)[len(Aucs2)//2]\n",
    "\n",
    "plt.plot(fprs[median_idx],tprs[median_idx],lw=1.0,color='g')\n",
    "\n",
    "ax=plt.plot([0, 1], [0, 1], color=\"navy\", lw=1, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Random Crossvalidation\")\n",
    "# plt.text(0.38, 0.11,\"Accuracy=0.8131\")\n",
    "# plt.legend(loc=\"lower right\")\n",
    "plt.axis('square')\n",
    "plt.tight_layout()\n",
    "plt.savefig('PINNPlotsGallen/rocrandValrv1.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.boxplot(Aucs2)\n",
    "plt.ylim(0.5,1)\n",
    "plt.savefig('PINNPlotsGallen/violin_randomvalrv2.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(Aucs)\n",
    "plt.ylim(0.5,1)\n",
    "plt.savefig('PINNPlotsGallen/violin_spvalrv2.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot all confusion maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot \n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np \n",
    "import geopandas as gpd\n",
    "%load_ext autoreload\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "# import GallenModel as ClassificationModelsimple\n",
    "import geopandas as gpd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "rcl_indexes=[]\n",
    "df=gpd.read_file('Data/NepalEqUSGSGallen.gpkg')\n",
    "df = df[df.Slp_m>10.0]\n",
    "kf = KFold(n_splits=10,random_state=42,shuffle=True)\n",
    "kf.get_n_splits(df)\n",
    "i=0\n",
    "for train_index, test_index in kf.split(df):\n",
    "    rcl_indexes.append(test_index)\n",
    "\n",
    "for i in range(0,10):\n",
    "    print(i)\n",
    "    preds=np.load(f'crossval_resultsGallen/RvPredsrv1_{str(i)}.npy')\n",
    "    truths=np.load(f'crossval_resultsGallen/RvTruthsrv1_{str(i)}.npy')\n",
    "\n",
    "    #confusion  map\n",
    "    confusiondata=np.empty(truths.shape,dtype=object)\n",
    "    confusiondata[np.bitwise_and(truths.flatten()==1,np.rint(preds.flatten())==1)]='True Positive'\n",
    "    confusiondata[np.bitwise_and(truths.flatten()==0,np.rint(preds.flatten())==1)]='False Positive'\n",
    "    confusiondata[np.bitwise_and(truths.flatten()==1,np.rint(preds.flatten())==0)]='False Negative'\n",
    "    confusiondata[np.bitwise_and(truths.flatten()==0,np.rint(preds.flatten())==0)]='True Negative'\n",
    "    sel_idx=rcl_indexes[i].tolist()\n",
    "    df.loc[sel_idx,'rcl_confusion']=confusiondata\n",
    "df_rc=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=gpd.read_file('Data/NepalEqUSGSGallen.gpkg')\n",
    "df = df[df.Slp_m>10.0]\n",
    "for i in range(1,11):\n",
    "    preds=np.load(f'crossval_resultsGallen/SpPredsrv2_{str(i)}.npy')\n",
    "    truths=np.load(f'crossval_resultsGallen/SpTruthsrv2_{str(i)}.npy')\n",
    "    print(i)\n",
    "    #confusion  map\n",
    "    confusiondata=np.empty(truths.shape,dtype=object)\n",
    "    confusiondata[np.bitwise_and(truths.flatten()==1,np.rint(preds.flatten())==1)]='True Positive'\n",
    "    confusiondata[np.bitwise_and(truths.flatten()==0,np.rint(preds.flatten())==1)]='False Positive'\n",
    "    confusiondata[np.bitwise_and(truths.flatten()==1,np.rint(preds.flatten())==0)]='False Negative'\n",
    "    confusiondata[np.bitwise_and(truths.flatten()==0,np.rint(preds.flatten())==0)]='True Negative'\n",
    "    sel_idx=df.index[df['id']==i].tolist()\n",
    "    df.loc[sel_idx,'scl_confusion']=confusiondata\n",
    "df_sc=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as cx\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "df_wm = df_sc.to_crs(epsg=3857)\n",
    "df_wm = df_wm[df_wm['Slp_m']>10.0]\n",
    "ax=df_wm.plot(column='scl_confusion',legend=False,figsize=(10, 10), alpha=0.6,linewidth=0)\n",
    "cx.add_basemap(ax,source='NASAGIBS.ASTER_GDEM_Greyscale_Shaded_Relief')\n",
    "ax.add_artist(ScaleBar(1))\n",
    "# ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.get_figure().savefig('PINNPlotsGallen/confusionmap_scvrv2.pdf',dpi=500,facecolor=ax.get_facecolor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as cx\n",
    "df_wm = df_rc.to_crs(epsg=3857)\n",
    "df_wm = df_wm[df_wm['Slp_m']>10.0]\n",
    "ax=df_wm.plot(column='rcl_confusion',legend=False,figsize=(10, 10), alpha=0.6,linewidth=0)\n",
    "cx.add_basemap(ax,source='NASAGIBS.ASTER_GDEM_Greyscale_Shaded_Relief')\n",
    "ax.add_artist(ScaleBar(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.get_figure().savefig('PINNPlotsGallen/confusionmap_rcvrv2.pdf',dpi=500,facecolor=ax.get_facecolor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=df_rc.rcl_confusion.value_counts().plot(kind='barh',logx=True,xlim=(10,1e4))\n",
    "ax.get_figure().savefig('PINNPlotsGallen/barplot_rcvrv2.pdf',dpi=500,facecolor=ax.get_facecolor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=df_sc.scl_confusion.value_counts().plot(kind='barh',logx=True,xlim=(10,1e4))\n",
    "ax.get_figure().savefig('PINNPlotsGallen/barplot_scvrv2.pdf',dpi=500,facecolor=ax.get_facecolor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Function Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsactivation(x):\n",
    "    # x=x-5.0\n",
    "    return 1/(1+np.exp(5-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.linspace(0,10,100)\n",
    "y=lsactivation(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "ax.set_xticks(np.arange(0, 11, 1))\n",
    "ax.set_yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.plot(x,y,label=r\"$p(s) = \\frac{1}{1+\\exp(5-D(s))}$\")\n",
    "plt.grid()\n",
    "plt.axvline(5.0, color='black')\n",
    "plt.axhline(0.50, color='black')\n",
    "plt.xlabel(\"Deformation (cm)\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.savefig(\"PINNPlotsGallen/landslideactivation.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "14679ae43342e2a47e22d3886e652cc2ab43a7731511cea5a972777e21e97d2a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
