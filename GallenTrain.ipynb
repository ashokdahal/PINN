{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import GallenModel as ClassificationModelsimple\n",
    "import geopandas as gpd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data\n",
    "df=gpd.read_file('Data/NepalEqUSGSGallen.gpkg')\n",
    "\n",
    "df = df[df.Slp_m>10.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.30, random_state=42)\n",
    "\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  df = dataframe.copy()\n",
    "  labels = df.pop('Landslide')\n",
    "  df = {key: value.to_numpy()[:,tf.newaxis] for key, value in df.items()}\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(batch_size)\n",
    "  return ds\n",
    "exai_ds=df_to_dataset(train_df[['Est_m','Nrt_m','HC_m','VC_m','Slp_m','Prc_m','NDVI_m','PGA_Usgs','Sand_m','Silt_m','Clay_m','Bdod_m','GLG','Landslide']])\n",
    "val_ds=df_to_dataset(test_df[['Est_m','Nrt_m','HC_m','VC_m','Slp_m','Prc_m','NDVI_m','PGA_Usgs','Sand_m','Silt_m','Clay_m','Bdod_m','GLG','Landslide']],shuffle=False)\n",
    "[(train_features, label_batch)] = exai_ds.take(1)\n",
    "print('Every feature:', list(train_features.keys()))\n",
    "print('A batch of geology:', train_features['GLG'])\n",
    "print('A batch of targets:', label_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df.PGA_Usgs.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "  # Create a layer that turns strings into integer indices.\n",
    "  if dtype == 'string':\n",
    "    index = layers.StringLookup(max_tokens=max_tokens)\n",
    "  # Otherwise, create a layer that turns integer values into integer indices.\n",
    "  else:\n",
    "    index = layers.IntegerLookup(max_tokens=max_tokens)\n",
    "\n",
    "  # Prepare a `tf.data.Dataset` that only yields the feature.\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the set of possible values and assign them a fixed integer index.\n",
    "  index.adapt(feature_ds)\n",
    "\n",
    "  # Encode the integer indices.\n",
    "  encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "\n",
    "  # Apply multi-hot encoding to the indices. The lambda function captures the\n",
    "  # layer, so you can use them, or include them in the Keras Functional model later.\n",
    "  return lambda feature: encoder(index(feature))\n",
    "def get_normalization_layer(name, dataset):\n",
    "  # Create a Normalization layer for the feature.\n",
    "  normalizer = layers.Normalization(axis=None)\n",
    "\n",
    "  # Prepare a Dataset that only yields the feature.\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "  # Learn the statistics of the data.\n",
    "  normalizer.adapt(feature_ds)\n",
    "\n",
    "  return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Est_m','Nrt_m','HC_m','VC_m','Slp_m','Prc_m','NDVI_m','PGA_Usgs','Sand_m','Silt_m','Clay_m','Bdod_m','GLG','Landslide']].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "# Numerical features.\n",
    "numerical_cols=['Est_m', 'Nrt_m', 'HC_m', 'VC_m', 'Slp_m', 'Prc_m', 'NDVI_m', 'PGA_Usgs', 'Sand_m', 'Silt_m', 'Clay_m', 'Bdod_m']\n",
    "for header in numerical_cols:\n",
    "  numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "  normalization_layer = get_normalization_layer(header, exai_ds)\n",
    "  encoded_numeric_col = normalization_layer(numeric_col)\n",
    "  all_inputs.append(numeric_col)\n",
    "  encoded_features.append(encoded_numeric_col)\n",
    "\n",
    "categorical_cols = ['GLG']\n",
    "\n",
    "for header in categorical_cols:\n",
    "  categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
    "  encoding_layer = get_category_encoding_layer(name=header,\n",
    "                                               dataset=exai_ds,\n",
    "                                               dtype='string',\n",
    "                                               max_tokens=9)\n",
    "  encoded_categorical_col = encoding_layer(categorical_col)\n",
    "  all_inputs.append(categorical_col)\n",
    "  encoded_features.append(encoded_categorical_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "clfmdl=ClassificationModelsimple.LandslideModel()\n",
    "clfmdl.getclassificationModel(all_inputs=all_inputs, encoded_features=encoded_features)\n",
    "clfmdl.getOptimizer()\n",
    "clfmdl.compileModel()\n",
    "clfmdl.model.load_weights('TrainedWeights/PINN_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "clfmdl.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def trainmodel(model,train_ds,val_ds):\n",
    "    \n",
    "    NUMBER_EPOCHS = 100\n",
    "    filepath='TrainedWeights/PINN_v3'\n",
    "    BATCH_SIZE=128\n",
    "    \n",
    "    model_checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor=\"val_auc\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode=\"max\",\n",
    "        save_freq=\"epoch\",\n",
    "        options=None\n",
    "    )\n",
    "    print(type(train_ds))\n",
    "    hist = model.fit(train_ds,\n",
    "                     epochs=NUMBER_EPOCHS,\n",
    "                     batch_size=BATCH_SIZE,\n",
    "                     validation_data=val_ds,\n",
    "                    #  validation_split=0.2,#auto validate using 20% of random samples at each epoch\n",
    "                     verbose=1, callbacks=[model_checkpoint_callback],class_weight = {0: 1, 1: 5}\n",
    "\n",
    "                    )\n",
    "    return hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# trainmodel(clfmdl.model,exai_ds,val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  tf.keras.models.load_model(\"TrainedWeights/PINN_v3/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=test_df['Landslide'].to_numpy()\n",
    "preds=model.predict(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fpr,tpr,thresholds=sklearn.metrics.roc_curve(y_test, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.auc(fpr,tpr))\n",
    "print(sklearn.metrics.confusion_matrix(y_test,np.rint(preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4),dpi=300)\n",
    "lw = 0.6\n",
    "plt.plot(\n",
    "    fpr,\n",
    "    tpr,\n",
    "    color=\"darkorange\",\n",
    "    lw=lw,\n",
    "    label=\"ROC curve (area = %0.2f)\" % sklearn.metrics.auc(fpr,tpr),\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Landslide Classification\")\n",
    "plt.text(0.61, 0.15,f\"Accuracy={round(sklearn.metrics.balanced_accuracy_score(y_test, preds>0.5),2)}\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.axis('square')\n",
    "plt.savefig('PINNPlots/rocrev1.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion  map\n",
    "all_data=df_to_dataset(df[['Est_m','Nrt_m','HC_m','VC_m','Slp_m','Prc_m','NDVI_m','PGA_Usgs','Sand_m','Silt_m','Clay_m','Bdod_m','GLG','Landslide']],shuffle=False)\n",
    "preds2=model.predict(all_data)\n",
    "Ydata=df['Landslide'].to_numpy()\n",
    "confusiondata=np.empty(Ydata.shape,dtype=object)\n",
    "confusiondata[np.bitwise_and(Ydata==1,np.rint(preds2.flatten())==1)]='True Positive'\n",
    "confusiondata[np.bitwise_and(Ydata==0,np.rint(preds2.flatten())==1)]='False Positive'\n",
    "confusiondata[np.bitwise_and(Ydata==1,np.rint(preds2.flatten())==0)]='False Negative'\n",
    "confusiondata[np.bitwise_and(Ydata==0,np.rint(preds2.flatten())==0)]='True Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['confusion']=confusiondata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as cx\n",
    "df_wm = df.to_crs(epsg=3857)\n",
    "ax=df_wm.plot(column='confusion',legend=True,figsize=(10, 10), alpha=0.7)\n",
    "cx.add_basemap(ax,source='NASAGIBS.ASTER_GDEM_Greyscale_Shaded_Relief')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.get_figure().savefig('PINNPlots/confusionmaprev1.pdf',facecolor=ax.get_facecolor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion  map\n",
    "all_data=df_to_dataset(df[['Est_m','Nrt_m','HC_m','VC_m','Slp_m','Prc_m','NDVI_m','PGA_Usgs','Sand_m','Silt_m','Clay_m','Bdod_m','GLG','Landslide']],shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as cx\n",
    "df_wm = df.to_crs(epsg=3857)\n",
    "geo_Tech = tf.keras.Model(inputs=model.input, outputs=model.get_layer(\"cohesion\").output)*5 # apply linear scaling to compensate for the 5x scaling on loss function\n",
    "geotech_preds=geo_Tech.predict(all_data)\n",
    "df_wm['cohesion'] = geotech_preds#*1000\n",
    "ax=df_wm.plot(column='cohesion',legend=True,figsize=(10, 10), alpha=0.7)#, vmin=1, vmax=3)\n",
    "cx.add_basemap(ax,source='NASAGIBS.ASTER_GDEM_Greyscale_Shaded_Relief')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wm['cohesion'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as cx\n",
    "# df_wm = df.to_crs(epsg=3857)\n",
    "geo_Tech = tf.keras.Model(inputs=model.input, outputs=model.get_layer(\"internalFriction\").output)\n",
    "geotech_preds=geo_Tech.predict(all_data)\n",
    "df_wm['internalFriction'] = np.rad2deg(geotech_preds)\n",
    "ax=df_wm.plot(column='internalFriction',legend=True,figsize=(10, 10), alpha=0.7)\n",
    "cx.add_basemap(ax,source='NASAGIBS.ASTER_GDEM_Greyscale_Shaded_Relief')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wm['internalFriction'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "df_wm['cohesion'] = df_wm['cohesion']*1000\n",
    "\n",
    "safety_factor = (df_wm.cohesion.to_numpy()*(1/(2300*9.81*np.sin(np.deg2rad(df_wm.Slp_m.to_numpy()))))) + ( np.tan(df_wm.internalFriction.to_numpy())/np.tan(np.deg2rad(df_wm.Slp_m.to_numpy())))\n",
    "\n",
    "# safety_factor = tf.nn.relu(safety_factor)\n",
    "safety_factor = tf.clip_by_value(safety_factor, 1.2, 15.0).numpy()\n",
    "\n",
    "ac = ((safety_factor-1)*9.81*np.sin(np.deg2rad(df_wm.Slp_m)))\n",
    "\n",
    "acpg=ac/(df_wm.PGA_Usgs.to_numpy()*10)\n",
    "\n",
    "acpg = tf.clip_by_value(acpg, 0.001, 0.999).numpy()\n",
    "\n",
    "powcomp = np.power((1-acpg),2.53)*np.power(acpg,-1.438)\n",
    "logds = 0.251+np.log(powcomp)+0.5\n",
    "\n",
    "displacement = np.exp(logds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wm['ac'] = ac/9.8\n",
    "df_wm['sf'] = safety_factor\n",
    "df_wm['displacement'] = displacement\n",
    "df_wm['acpg'] = acpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wm['ac'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wm['aci'] = 1/df_wm['ac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wm['sf'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wm['displacement'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wm['susceptibility']=preds2.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "fig,axs = plt.subplots(1,2,dpi=500, figsize=(10,5))\n",
    "\n",
    "df_wm = df_wm[df_wm['Slp_m']>10]\n",
    "\n",
    "df_wm.plot(column='ac',cmap='viridis', legend=True, alpha=0.7,  ax=axs[0],vmin=0.0,vmax=0.50, legend_kwds={\"label\": \"Critical Accelerations ($m/s^2$)\", \"orientation\": \"horizontal\"},)\n",
    "cx.add_basemap(axs[0],source='NASAGIBS.ASTER_GDEM_Greyscale_Shaded_Relief')\n",
    "axs[0].set_axis_off()\n",
    "axs[0].add_artist(ScaleBar(1))\n",
    "\n",
    "df_wm.plot(column='susceptibility',cmap='RdYlGn_r',legend=True, alpha=0.7,  ax=axs[1], vmin=0.0, vmax = 1.0, legend_kwds={\"label\": \"Susceptibility\", \"orientation\": \"horizontal\"},)\n",
    "cx.add_basemap(axs[1],source='NASAGIBS.ASTER_GDEM_Greyscale_Shaded_Relief')\n",
    "axs[1].set_axis_off()\n",
    "\n",
    "plt.savefig(\"PINNPlotsGallen/Products.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wm = df_wm[df_wm['Slp_m']>10]\n",
    "df_wm=df_wm.to_crs(epsg=4326)\n",
    "ax= df_wm.plot(column='Landslide', legend=True,categorical=True, alpha=0.7,vmin=0.0,vmax=1,)\n",
    "cx.add_basemap(ax,source='NASAGIBS.ASTER_GDEM_Greyscale_Shaded_Relief')\n",
    "# ax.set_axis_off()\n",
    "ax.add_artist(ScaleBar(1))\n",
    "plt.savefig(\"PINNPlotsGallen/StudyArea.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlgeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
